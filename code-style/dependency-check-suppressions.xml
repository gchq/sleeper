<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright 2022-2024 Crown Copyright
  ~
  ~ Licensed under the Apache License, Version 2.0 (the "License");
  ~ you may not use this file except in compliance with the License.
  ~ You may obtain a copy of the License at
  ~
  ~     http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->
<suppressions xmlns="https://jeremylong.github.io/DependencyCheck/dependency-suppression.1.3.xsd">
    <suppress>
        <notes><![CDATA[
        Spark is suppressed as the version we are able to use is restricted by support in AWS EMR:
        https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.apache\.spark/.*$</packageUrl>
        <cpe>cpe:/a:apache:spark:3.5.1</cpe>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Spark is suppressed as the version we are able to use is restricted by support in AWS EMR:
        https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html

        Some of the Spark dependencies were not identified by the Spark CPE, so we've added this to catch
        several shaded dependencies.
        ]]></notes>
        <filePath regex="true">^.*/spark-[^/]+-3\.5\.1\.jar/.*$</filePath>
        <vulnerabilityName regex="true">.*</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Hadoop is suppressed as the version we are able to use is restricted by support in AWS EMR:
        https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.apache\.hadoop/.*$</packageUrl>
        <cpe>cpe:/a:apache:hadoop:3.3.6</cpe>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Hadoop is suppressed as the version we are able to use is restricted by support in AWS EMR:
        https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html

        Some of the Hadoop dependencies were not identified by the Hadoop CPE, so we've added this to catch
        several shaded dependencies.
        ]]></notes>
        <filePath regex="true">^.*/hadoop-client-[^/]+-3\.3\.6\.jar/.*$</filePath>
        <vulnerabilityName regex="true">.*</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Hadoop is suppressed as the version we are able to use is restricted by support in AWS EMR:
        https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.apache\.hadoop/hadoop-common@.*$</packageUrl>
        <vulnerabilityName>CVE-2024-23454</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The version of Hadoop we're using uses an old version of Jackson, with old Maven artifacts that don't have a
        fixed version.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.codehaus\.jackson/jackson\-mapper\-asl@.*$</packageUrl>
        <vulnerabilityName>CVE-2017-7525</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The version of Hadoop we're using uses an old version of Jackson, with old Maven artifacts that don't have a
        fixed version.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.codehaus\.jackson/jackson\-mapper\-asl@.*$</packageUrl>
        <vulnerabilityName>CVE-2019-10172</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The version of Hadoop we're using uses an old version of OkHttp, with old Maven artifacts that don't have a
        fixed version.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/com\.squareup\.okhttp/okhttp@.*$</packageUrl>
        <vulnerabilityName>CVE-2021-0341</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The version of Hadoop we're using uses an old version of OkHttp, with old Maven artifacts that don't have a
        fixed version.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/com\.squareup\.okhttp/okhttp@.*$</packageUrl>
        <vulnerabilityName>CVE-2023-0833</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The version of Spark we're using uses an old version of Zookeeper, and to get a fixed version we'd need a
        significant upgrade.

        All the Zookeeper communication takes place within a Spark cluster, so this shouldn't be a serious problem.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.apache\.zookeeper/(zookeeper|zookeeper\-jute)@3.6.3$</packageUrl>
        <vulnerabilityName regex="true">CVE-2023-44981|CVE-2024-23944</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The version of Athena we're using uses an old version of Bouncy Castle Provider, with an old Maven artifact that
        doesn't have a fixed version.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.bouncycastle/bcprov\-jdk15on@.*$</packageUrl>
        <vulnerabilityName regex="true">CVE-2023-33201|CVE-2024-29857|CVE-2024-30172|CVE-2024-30171|CVE-2024-34447</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The AWS CDK uses Javascript code with a vulnerable NPM package. Once there's a version of the CDK that doesn't,
        we can use that instead.
        ]]></notes>
        <filePath regex="true">^.*/cdk-asset-awscli-v1-[.0-9]+\.jar/.*$</filePath>
        <cve>CVE-2021-23497</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The AWS CDK uses a vulnerable Ruby gem. Once there's a version of the CDK that doesn't, we can use that instead.
        ]]></notes>
        <filePath regex="true">^.*/cdk-asset-awscli-v1-[.0-9]+\.jar/.*$</filePath>
        <cve>CVE-2020-10663</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        This seems to be a false positive where dependency check is reporting the CVE against the wrong artifact.
        The CVE states the vulnerability is in the AWS S3 SDK before version 1.12.261.
        We're using a version of that library that has the fix.
        The aws-crt library is still used with the same version after the fix was applied in the S3 SDK.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/software\.amazon\.awssdk\.crt/aws\-crt@.*$</packageUrl>
        <cve>CVE-2022-31159</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        At time of writing, the latest version of Avro IPC uses an old version of jQuery in its static pages for stats.
        We don't expose that page, so it won't be a problem.
        This is a provided dependency for the module bulk-import/bulk-import-runner.
        ]]></notes>
        <filePath regex="true">^.*/avro-ipc-1\.12\.0\.jar/.*/jquery-.*\.js$</filePath>
        <vulnerabilityName regex="true">.*</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        This seems to be a false positive as the CVE is for the Go implementation of Avro, which we're not using.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.apache\.avro/avro\-(ipc|mapred)@.*$</packageUrl>
        <cve>CVE-2023-37475</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Janino/commons-compiler is used by Spark SQL to compile SQL. Our tests against Spark fail with the latest
        version of Janino, and we can't upgrade Spark because we're restricted by support in AWS EMR:
        https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-release-components.html
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.codehaus\.janino/(commons\-compiler|janino)@.*$</packageUrl>
        <cve>CVE-2023-33546</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Spark SQL integrates with Apache Hive, but we don't use it.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.apache\.hive/hive\-storage\-api@.*$</packageUrl>
        <cve>CVE-2021-34538</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        This is a stack overflow caused by trying to build JSON from a data structure with cyclic dependencies.
        There's no version of Jackson available with a fix yet, and it seems very unlikely that there's a case where
        this could happen in Sleeper.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/com\.fasterxml\.jackson\.core/jackson\-databind@.*$</packageUrl>
        <cve>CVE-2023-35116</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        This is a false positive. According to the issue linked on the CVE, the problem is limited to the
        okhttp-brotli library, which we don't use.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/com\.squareup\.(okhttp3|okhttp)/okhttp@.*$</packageUrl>
        <cve>CVE-2023-3782</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        The problem here is that Netty does not enable hostname verification by default. This is still a problem in the
        latest version of Netty. We don't use this directly. It's a dependency for Spark, Athena, and AWS clients,
        eg. for S3.

        There isn't a fixed version of Netty, and the libraries we're using may configure hostname verification
        correctly. We may see CVEs against those libraries separately if this doesn't get fixed.

        It's not clear how we would solve this ourselves, and the relevant network calls all happen within a private
        VPC.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/io\.netty/netty.*@.*$</packageUrl>
        <vulnerabilityName>CVE-2023-4586</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Netty is a dependency for Spark, Athena, and AWS clients, eg. for S3.

        This is about the HTTP/2 rapid reset vulnerability. We don't expose an HTTP server publicly, so this shouldn't
        be a problem for us.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/io\.netty/netty.*@.*$</packageUrl>
        <vulnerabilityName>CVE-2023-44487</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Bouncy Castle is a dependency for Athena. We also use the library in the build module but we use a more recent
        version that is not vulnerable.

        Athena declares a dependency on an old Maven artifact targeted at JDK 1.5, and there's no updated version of
        that artifact.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.bouncycastle/bcprov\-jdk15on@.*$</packageUrl>
        <cve>CVE-2023-33202</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Amazon Ion is a dependency for AWS. At time of writing, the latest version of the AWS Java SDK v1 uses an old
        artifact for Ion, which does not have a version without this vulnerability.

        Since these libraries are only used to interact with the AWS API, this may not be a problem. It's possible we
        may need to upgrade to version 2 of the AWS Java SDK in order to get a version of Ion with this fixed.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/software\.amazon\.ion/ion\-java@.*$</packageUrl>
        <cve>CVE-2024-21634</cve>
    </suppress>
    <suppress>
        <notes><![CDATA[
        XNIO is a dependency for Hadoop, used by Kerby's kerb-admin module, which is a transitive dependency for Hadoop
        authentication. At time of writing, there's no version of XNIO without this problem.

        Since HDFS is not used, it doesn't seem like this should be needed as a dependency. We can look at removing this
        from the classpath.

        We're using Hadoop for our integration with Parquet, and for bulk import jobs on Spark. The Parquet integration
        only talks to S3 in practice, although the Hadoop integration is designed for HDFS, which may be why this is a
        dependency. Spark also seems to only use Hadoop authentication when talking to HDFS:

        https://spark.apache.org/docs/latest/security.html#kerberos
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.jboss\.xnio/xnio\-api@.*$</packageUrl>
        <vulnerabilityName>CVE-2023-5685</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        JGraphT is used in the build module to visualise the dependencies between Maven modules. This is not used in
        production code, and there is not a more up to date version that does not have this problem.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.jgrapht/jgrapht\-core@.*$</packageUrl>
        <vulnerabilityName regex="true">CVE-2024-23078|CVE-2024-23079</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Apfloat is used in the build module by JUNG for visualising dependencies between Maven modules. This is not used
        in production code, and there is not a more up to date version that does not have this problem.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.apfloat/apfloat@.*$</packageUrl>
        <vulnerabilityName regex="true">CVE-2024-23086|CVE-2024-23084|CVE-2024-23085</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Joda Time is used by most of the AWS SDK v1 dependencies, by the Trino Plugin Toolkit, and by the AWS Lambda
        API. There is currently no version of the library without this vulnerability, and the vulnerability itself is
        disputed.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/joda\-time/joda\-time@.*$</packageUrl>
        <vulnerabilityName>CVE-2024-23080</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        Jetty Servlets is only used by WireMock, which is only used for tests. The CVE also seems to incorrectly match
        the version we're using. It's listed as having been patched in version 9.4.52, and we're using 9.4.56 at time of
        writing.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.eclipse\.jetty/jetty-servlets@.*$</packageUrl>
        <vulnerabilityName>CVE-2023-36479</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        We're not using the HttpURI class directly, and the CVE states that Jetty is not vulnerable unless you use that
        directly.
        ]]></notes>
        <packageUrl regex="true">^^pkg:maven/org\.eclipse\.jetty\*$</packageUrl>
        <vulnerabilityName>CVE-2024-6763</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        DOMPurify is only used by WireMock, which is only used for tests. We're not able to upgrade to a later version
        of WireMock that doesn't use this. Later versions of WireMock use Jetty 11 or 12, and the version of Hadoop
        we're using uses Jetty 9.
        ]]></notes>
        <packageUrl regex="true">^pkg:javascript/DOMPurify@.*$</packageUrl>
        <vulnerabilityName regex="true">CVE-2024-45801|CVE-2024-47875|CVE-2024-48910</vulnerabilityName>
    </suppress>
    <suppress>
        <notes><![CDATA[
        This seems to be a false positive, as the CVE is for Eclipse Glassfish, which isn't on the classpath for Sleeper
        anywhere. The dependency it flagged is for HK2, which is a dependency injection framework used by both Glassfish
        and Jersey. We only have Jersey and not Glassfish. The version number it's flagged is also specific to the OSGi
        Resource Locator, and not Glassfish, and it's comparing it to the vulnerable version of Glassfish.
        ]]></notes>
        <packageUrl regex="true">^pkg:maven/org\.glassfish\.hk2/osgi-resource-locator@.*$</packageUrl>
        <cve>CVE-2024-9329</cve>
    </suppress>
</suppressions>
